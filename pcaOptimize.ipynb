{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework1-1a.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k44AvudpIsWa",
        "colab_type": "text"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write a function to calculate the change in computation time and prediction accuracy per principal component added to the feature set for kNN. Have your function call be pcaCompare(X,Y,rows,k,pcs), where X, Y, and k are the usual inputs to kNN, rows is the rows of the data we want to test, and pcs is the maximum number of principal components tested. Have it return a 3 column matrix representing the change in time and accuracy (not as a percentage) that occurs by adding this PC as a feature (eg. negative indicates the value went down when it was added) in the first and second columns, respectively, and the variance of the PC in the third, where the PC number is the row number.**bold text**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yhfvEs7J2rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNN(X,Y,newx,k,regress=True,allK=False,leave1out=False,scaleX=True,scaler='standard'):\n",
        "\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "\n",
        "  from sklearn.neighbors import KNeighborsClassifier \n",
        "  from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  #from sklearn.preprocessing import MinMaxScaler\n",
        "  #from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "  from statistics import mean \n",
        "  from statistics import mode\n",
        "  from collections import Counter\n",
        "\n",
        "  def kNNtype(neighbs,regress):\n",
        "    if regress:\n",
        "      knn = KNeighborsRegressor(n_neighbors=neighbs)\n",
        "    else:\n",
        "      knn = KNeighborsClassifier(n_neighbors=neighbs)\n",
        "    return knn\n",
        "\n",
        "  if scaler != 'standard':\n",
        "    scaler = scaler\n",
        "  else:\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "# Update: for row subsets/test sets in hw; fitting the scaing function should be done separate\n",
        "# so the same can be applied to train and test data (or X and newx) \n",
        "  if scaleX == True:\n",
        "    # scale should be fit to X/train\n",
        "    scaler.fit(X)\n",
        "    columns_X = [list(X.columns)]\n",
        "    for feature in columns_X:\n",
        "      X[feature] = scaler.transform(X[feature])\n",
        "      newx[feature] = scaler.transform(newx[feature])\n",
        "\n",
        "  knn_all = pd.DataFrame()\n",
        "  if allK == True:\n",
        "    if leave1out == True:\n",
        "      nn_all = []\n",
        "      for j in list(newx.index.values.tolist()):\n",
        "      #for j in list(Y.index.values.tolist()):\n",
        "        knn_row = []\n",
        "        knn = kNNtype(k+1,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = pd.DataFrame(newx.loc[j,:])\n",
        "        nn = knn.kneighbors(test.T)[1][0]\n",
        "        for i in range(2,k+1):\n",
        "          nn1 = nn[1:i] # leave one out\n",
        "          test = list(Y.iloc[nn1])\n",
        "          if regress:\n",
        "            test = mean(test)\n",
        "          else:\n",
        "            c = Counter(test)\n",
        "            l = list(c.values())\n",
        "            ind = l.index(max(c.values()))\n",
        "            test = list(c.keys())[ind]\n",
        "            # count number of times the max class occurs and if there is a tie\n",
        "            # choose the second class with the max if index is even\n",
        "            if (l.count(max(l))) > 1 and (j % 2 !=0):\n",
        "              l[ind] = 0\n",
        "              ind = l.index(max(c.values()))\n",
        "              test = list(c.keys())[ind]\n",
        "\n",
        "          knn_row.append(test)\n",
        "        knn_row = pd.DataFrame(knn_row)\n",
        "        knn_all = [knn_all, knn_row]\n",
        "        knn_all = pd.concat(knn_all,axis=1, ignore_index=True)\n",
        "        nn_all.append(list(nn1))\n",
        "      nn_all = np.array(nn_all)\n",
        "    else:\n",
        "        for i in range(1,k+1):\n",
        "          knn = kNNtype(i,regress)\n",
        "          knn.fit(X, Y)\n",
        "          test = knn.predict(newx)\n",
        "          knn_row = pd.DataFrame(test).T\n",
        "          knn_all = [knn_all, knn_row]\n",
        "          knn_all = pd.concat(knn_all,axis=0, ignore_index=True)\n",
        "        nn_all = knn.kneighbors(newx)[1]\n",
        "  else:\n",
        "    if leave1out == True:\n",
        "      knn_row = []\n",
        "      for j in list(newx.index.values.tolist()):\n",
        "      #for j in list(Y.index.values.tolist()):\n",
        "        knn = kNNtype(k,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = pd.DataFrame(newx.loc[j,:])\n",
        "        nn = knn.kneighbors(test.T)[1][0]\n",
        "        nn1 = nn[1:len(nn)]\n",
        "\n",
        "        test = list(Y.iloc[nn1])\n",
        "        if regress:\n",
        "            test = mean(test)\n",
        "        else:\n",
        "          c = Counter(test)\n",
        "          l = list(c.values())\n",
        "          ind = l.index(max(c.values()))\n",
        "          test = list(c.keys())[ind]\n",
        "          # count number of times the max class occurs and if there is a tie\n",
        "          # choose the second class with the max if index is even\n",
        "          if (l.count(max(l))) > 1 and (j % 2 !=0):\n",
        "            l[ind] = 0\n",
        "            ind = l.index(max(c.values()))\n",
        "            test = list(c.keys())[ind]\n",
        "\n",
        "        knn_row.append(test)\n",
        "      knn_all = pd.DataFrame(knn_row).T\n",
        "      nn_all = nn1\n",
        "    else:\n",
        "        knn = kNNtype(k,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = knn.predict(newx)\n",
        "        knn_all = pd.DataFrame(test)\n",
        "        nn_all = knn.kneighbors(newx)[1]\n",
        "\n",
        "  return knn_all, nn_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USNQRj7pPg-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findOverallLoss(ypreds,Y):\n",
        "  err = abs(ypreds.reset_index(drop=True).T - Y.reset_index(drop=True).values.squeeze())\n",
        "  MAPE = err.mean(axis=1)\n",
        "  return MAPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CDEgqj4bs04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pcaCompare(X,Y,rows,k, pcs):\n",
        "  from sklearn.decomposition import PCA\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.metrics import r2_score\n",
        "\n",
        "  train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=rows, random_state=1)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(train_X)\n",
        "\n",
        "  train_X = scaler.transform(train_X)\n",
        "  test_X = scaler.transform(test_X)\n",
        "  #newx = scaler.transform(rows)\n",
        "  x = 1\n",
        "\n",
        "  time_pca = []\n",
        "  var = []\n",
        "  acc = []\n",
        "  basetime = 0 \n",
        "\n",
        "  time_acc_var = pd.DataFrame(columns=['Time','Accuracy','Variance'])\n",
        "  start = time.time()\n",
        "  out,neighbors = kNN(train_X, train_Y, test_X, k,regress=True,scaleX = False) # regress = True \n",
        "  basetime = time.time() - start\n",
        "  print(\"--- kNN without pca %s seconds ---\" % basetime)\n",
        "  knnscore = r2_score(test_Y, out)\n",
        "  print(\"--- kNN score without pca %s ---\" % knnscore)\n",
        "\n",
        "  while x <= pcs:\n",
        "    pca = PCA(n_components = x)\n",
        "    pca.fit(train_X)\n",
        "   # print(\"--- %s pc ---\" % (pca.n_components_))\n",
        "    X_pca = pca.transform(train_X)\n",
        "    newx_pca = pca.transform(test_X)\n",
        "    start_time = time.time()\n",
        "    knnout, nn = kNN(X_pca, train_Y, newx_pca, k,regress=True,scaleX=False)\n",
        "   # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "    pcatime = (time.time() - start_time)\n",
        "    time_pca.append(pcatime - basetime)\n",
        "    #print(\"--- %s accuracy score ---\" % r2_score(test_Y,knnout))\n",
        "    pcascore = r2_score(test_Y,knnout) # change to change in acc \n",
        "    acc.append(knnscore - pcascore)\n",
        "   # print(\"--- %s variance ---\" % pca.explained_variance_ratio_[x - 1])\n",
        "    var.append(pca.explained_variance_ratio_[x - 1])\n",
        "    x += 1\n",
        "\n",
        "  for i in range(len(acc)):\n",
        "    time_acc_var.loc[i+1, 'Time'] = time_pca[i]\n",
        "    time_acc_var.loc[i+1, 'Accuracy'] = acc[i]\n",
        "    time_acc_var.loc[i+1, 'Variance'] = var[i]\n",
        "    \n",
        "  return time_acc_var, knnscore, basetime\n",
        "\n",
        "    # writing to data frame\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRW6qEgsMrCm",
        "colab_type": "text"
      },
      "source": [
        "Write a wrapper function for pcaCompare to find the best number of PCs for the optimal runtime and a loss no greater than maxLoss. Have your function call be pcaOptimize(X,Y,rows,k,pcs,maxLoss), where X, Y, rows, k, and pcs are the same as above, and maxLoss is the maximum acceptable average loss as a percentage of the loss without using pca (eg. maxLoss=1.1 then it can be 10% higher.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSyhN_jvHxU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pcaOptimize(X,Y, rows,k,pcs,maxLoss):\n",
        "    table, knnscore, knntime = pcaCompare(X,Y, rows, k, pcs)\n",
        "    scorerange = (maxLoss - int(maxLoss)) * knnscore\n",
        "    acceptable = knnscore - scorerange\n",
        "    print(acceptable)\n",
        "    answer  = 0 \n",
        "    timetable = []\n",
        "    rslt = table.loc[table['Accuracy'] >= acceptable]\n",
        "    print(rslt)\n",
        "    \n",
        "    timetable = rslt['Time']\n",
        "    answer = min(timetable)\n",
        "    print(answer)\n",
        "    x = 1\n",
        "    for row in range(len(timetable)):\n",
        "      if (answer == timetable[row + 1]):\n",
        "        print(\"Best PC for optimization is : %s \" %x)\n",
        "      x += 1\n",
        "  \n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VuO6Eu4E7xf",
        "colab_type": "code",
        "outputId": "0fd12f99-ad39-4327-81d7-3d773ab6831f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "for i in retur:\n",
        "  print(i)\n",
        "  print('space')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Time   Accuracy   Variance\n",
            "1  -81.8509   0.227006   0.115031\n",
            "2  -83.1206   0.182116  0.0779065\n",
            "3  -82.9737   0.198894  0.0590757\n",
            "4  -82.9621   0.190459  0.0419953\n",
            "5  -82.9397   0.186404  0.0375025\n",
            "6  -82.7193   0.127346  0.0277753\n",
            "7  -82.7128   0.146261  0.0235918\n",
            "8  -82.4571   0.142665  0.0230555\n",
            "9  -82.0935   0.131458  0.0208272\n",
            "10 -81.6889   0.133016  0.0200892\n",
            "11 -81.0395   0.142928  0.0187709\n",
            "12 -80.3735   0.114991  0.0182263\n",
            "13 -79.6306  0.0871631  0.0178589\n",
            "14   -78.72  0.0849886  0.0167321\n",
            "15 -77.6382  0.0889212  0.0160166\n",
            "space\n",
            "0.2071908405364502\n",
            "space\n",
            "83.70735287666321\n",
            "space\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn59S4mIITMc",
        "colab_type": "code",
        "outputId": "ba54f83f-532f-4831-8524-df36290db9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/drive/My Drive/ecs171_yancey/Lecture_Notes/Chapter_3/YearPredictionMSD.txt'\n",
        "\n",
        "# load CSV using pandas library\n",
        "ms = pd.read_csv(my_path, header=None)\n",
        "ms.head()\n",
        "#print(ms.info())\n",
        "sqrt(len(ms))\n",
        "\n",
        "Y = ms.iloc[:,0]\n",
        "X = ms.iloc[:,1:]\n",
        "#newx = X.iloc[0:1000,:]\n",
        "pcaOptimize(X,Y,200, 12, 5, 1.1)\n",
        "# table, score, basetime = pcaCompare(X,Y,200,120,15)\n",
        "# table[1] == table[\"Accuracy\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "--- kNN without pca 94.75120449066162 seconds ---\n",
            "--- kNN score without pca 0.28190375461133266 ---\n",
            "0.25371337915019937\n",
            "      Time  Accuracy   Variance\n",
            "1 -91.8024    0.4367   0.115031\n",
            "2  -93.964   0.31622  0.0779065\n",
            "3 -93.9599  0.342466  0.0590757\n",
            "4  -93.815  0.318696  0.0419954\n",
            "5 -93.5523  0.338456  0.0375027\n",
            "-93.96401572227478\n",
            "Best PC for optimization is : 2 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}